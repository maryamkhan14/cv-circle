#!/bin/bash
# Credit: https://github.com/confluentinc/demo-scene/blob/master/kafka-connect-zero-to-hero/demo_zero-to-hero-with-kafka-connect.adoc
set -e
sleep 5
echo -e "\n\n=============\nWaiting for Kafka Connect to start listening on localhost ‚è≥\n=============\n"
while [ $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) -ne 200 ] ; do
  echo -e "\t" $(date) " Kafka Connect listener HTTP state: " $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) " (waiting for 200)"
  sleep 5
done
echo -e $(date) "\n\n--------------\n\o/ Kafka Connect is ready! Listener HTTP state: " $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) "\n--------------\n"

sleep 2
echo -e "\nAdding Redis Kafka Source Connector for the 'cache_auth' stream:"
curl -X POST -H "Content-Type: application/json" --data '
  {"name": "redis-source",
   "config": {
    "name": "redis-source",
    "tasks.max":"1",
    "connector.class":"com.redis.kafka.connect.RedisSourceConnector",
    "redis.uri":"redis://users-redis:6379",
    "redis.stream.name":"cache_auth",
    "topic": "kafka_auth",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "value.converter.schema.registry.url": "http://schema-registry:8081"
}}' http://localhost:8083/connectors

sleep 2
echo -e "\nCreating necessary topics:"
retries=0

streams=$(curl -X POST http://ksqldb:8088/ksql -d '{"ksql": "SHOW STREAMS;"}')
echo "Found these streams:" $streams
if [[ $streams != *"SOURCE_RECORDS"* ]] || [[ $streams != *"UNKEYED_SESSION_DETAILS"* ]] || [[ $streams != *"KEYED_SESSION_DETAILS"* ]]; then
  echo "Need to create streams. Creating..."
  while [ $(curl -s -o /dev/null -w %{http_code} -X POST http://ksqldb:8088/ksql -d '{"ksql": "CREATE STREAM IF NOT EXISTS source_records WITH (KAFKA_TOPIC='\''kafka_auth'\'', KEY_FORMAT='\''KAFKA'\'', VALUE_FORMAT='\''AVRO'\'');CREATE OR REPLACE STREAM unkeyed_session_details AS SELECT CAST(EXTRACTJSONFIELD(BODY['\''session'\''], '\''$.sessionId'\'') AS STRING) AS ID, CAST(EXTRACTJSONFIELD(BODY['\''session'\''], '\''$.cookie'\'') AS STRING) AS cookie, CAST(EXTRACTJSONFIELD(BODY['\''session'\''], '\''$.user'\'') AS STRING) AS user from source_records;CREATE OR REPLACE STREAM keyed_session_details WITH (KAFKA_TOPIC='\''keyed_session_details'\'') AS SELECT * FROM unkeyed_session_details PARTITION BY ID;"}') -ne 200 ] ; do
    echo -e "\t" $(date) " Stream creation state not good (waiting for 200)"
    sleep 30
  done
  echo "Topics created successfully!"
fi

<<comment
sleep 2
echo -e "\nAdding Redis Kafka Sink Connector for the 'kafka_auth' topic into RedisJSON:"
curl -X POST -H "Content-Type: application/json" --data '
      {"name": "redis-sink-a",
      "config": {
        "name" : "redis-sink-a",
        "connector.class" : "com.github.jcustenborder.kafka.connect.redis.RedisSinkConnector",
        "tasks.max":"1",
        "topics":"keyed_session_details",
        "redis.hosts": "posts-redis:6379",
        "redis.database":0,
        "key.converter": "org.apache.kafka.connect.storage.StringConverter",
        "value.converter": "org.apache.kafka.connect.converters.ByteArrayConverter"
    }}' http://localhost:8083/connectors -w "\n"
comment